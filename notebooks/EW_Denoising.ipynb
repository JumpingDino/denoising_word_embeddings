{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embeddings\n",
    "\n",
    "**Usamos abaixo um Word2Vec CBOW de 50 dimensões.**\n",
    "\n",
    "### Como usamos o git como repositorio de código é indicado baixar os embeddings no link abaixo:\n",
    "\n",
    "http://nilc.icmc.usp.br/nilc/index.php/repositorio-de-word-embeddings-do-nilc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import pairwise\n",
    "from sklearn.metrics import pairwise_distances\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from utils import similarity\n",
    "\n",
    "def table_similarities(word:str,embedding_table:pd.DataFrame):\n",
    "    w1_str = word\n",
    "    w1 = np.array(embedding_table.loc[w1_str,:])\n",
    "\n",
    "    tab = similarity.cossim_vec2table(vec = w1,\n",
    "                            df = embedding_example,\n",
    "                            vec_title = w1_str,\n",
    "                            df_idx_title = 'word')\n",
    "    return tab\n",
    "\n",
    "#loading nathan embeddings\n",
    "word_embedding = pd.read_csv(\"cbow_s50.txt\",sep =' ').reset_index()\n",
    "\n",
    "#Renomeia as colunas\n",
    "col_names = [f'level_{i}' for i in range(0,51)]\n",
    "word_embedding.columns = col_names\n",
    "word_embedding = word_embedding.set_index('level_0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![word_embeddings](representacao_word.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1_df = table_similarities(word = 'homem',\n",
    "                   embedding_table = word_embedding)\n",
    "\n",
    "w2_df = table_similarities(word = 'mulher',\n",
    "                   embedding_table = word_embedding)\n",
    "\n",
    "cos_df = w1_df.merge(w2_df, left_on= 'word',right_on = 'word')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![word_embeddings](vies.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>similarity_homem</th>\n",
       "      <th>similarity_mulher</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>529</th>\n",
       "      <td>militar</td>\n",
       "      <td>0.138027</td>\n",
       "      <td>0.018290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>837</th>\n",
       "      <td>chefe</td>\n",
       "      <td>0.486461</td>\n",
       "      <td>0.173151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1758</th>\n",
       "      <td>policial</td>\n",
       "      <td>0.524237</td>\n",
       "      <td>0.106000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023</th>\n",
       "      <td>vice-presidente</td>\n",
       "      <td>0.323301</td>\n",
       "      <td>0.157920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2671</th>\n",
       "      <td>motorista</td>\n",
       "      <td>0.673756</td>\n",
       "      <td>0.104669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3585</th>\n",
       "      <td>auxiliar</td>\n",
       "      <td>0.169235</td>\n",
       "      <td>0.200137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6303</th>\n",
       "      <td>cientista</td>\n",
       "      <td>0.610675</td>\n",
       "      <td>0.151645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9279</th>\n",
       "      <td>analista</td>\n",
       "      <td>0.402622</td>\n",
       "      <td>0.136796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15033</th>\n",
       "      <td>taxista</td>\n",
       "      <td>0.802932</td>\n",
       "      <td>0.094569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48201</th>\n",
       "      <td>diarista</td>\n",
       "      <td>0.069297</td>\n",
       "      <td>0.684808</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  word  similarity_homem  similarity_mulher\n",
       "529            militar          0.138027           0.018290\n",
       "837              chefe          0.486461           0.173151\n",
       "1758          policial          0.524237           0.106000\n",
       "2023   vice-presidente          0.323301           0.157920\n",
       "2671         motorista          0.673756           0.104669\n",
       "3585          auxiliar          0.169235           0.200137\n",
       "6303         cientista          0.610675           0.151645\n",
       "9279          analista          0.402622           0.136796\n",
       "15033          taxista          0.802932           0.094569\n",
       "48201         diarista          0.069297           0.684808"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Uso de denominações neutras\n",
    "job_neutral = ['taxista','motorista','policial','militar','diarista','chefe','auxiliar','vice-presidente',\n",
    "               'analista','cientista',\n",
    "              ]\n",
    "\n",
    "cos_df[cos_df['word'].isin(job_neutral)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>similarity_homem</th>\n",
       "      <th>similarity_mulher</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1110</th>\n",
       "      <td>conhecimento</td>\n",
       "      <td>0.425448</td>\n",
       "      <td>0.096155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2325</th>\n",
       "      <td>medicina</td>\n",
       "      <td>0.076617</td>\n",
       "      <td>0.349645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2386</th>\n",
       "      <td>engenharia</td>\n",
       "      <td>-0.084514</td>\n",
       "      <td>0.205103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10233</th>\n",
       "      <td>enfermagem</td>\n",
       "      <td>0.048875</td>\n",
       "      <td>0.237265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17806</th>\n",
       "      <td>panela</td>\n",
       "      <td>0.168187</td>\n",
       "      <td>0.613136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90411</th>\n",
       "      <td>ciencia</td>\n",
       "      <td>-0.017541</td>\n",
       "      <td>0.373977</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               word  similarity_homem  similarity_mulher\n",
       "1110   conhecimento          0.425448           0.096155\n",
       "2325       medicina          0.076617           0.349645\n",
       "2386     engenharia         -0.084514           0.205103\n",
       "10233    enfermagem          0.048875           0.237265\n",
       "17806        panela          0.168187           0.613136\n",
       "90411       ciencia         -0.017541           0.373977"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kw_subst = ['panela','enfermagem','medicina','engenharia','ciencia','conhecimento']\n",
    "cos_df[cos_df['word'].isin(kw_subst)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>similarity_homem</th>\n",
       "      <th>similarity_mulher</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1352</th>\n",
       "      <td>juiz</td>\n",
       "      <td>0.552790</td>\n",
       "      <td>0.063067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1611</th>\n",
       "      <td>advogado</td>\n",
       "      <td>0.647213</td>\n",
       "      <td>0.076083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3205</th>\n",
       "      <td>engenheiro</td>\n",
       "      <td>0.528756</td>\n",
       "      <td>0.070841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8821</th>\n",
       "      <td>advogada</td>\n",
       "      <td>0.103379</td>\n",
       "      <td>0.709269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9638</th>\n",
       "      <td>enfermeira</td>\n",
       "      <td>0.145856</td>\n",
       "      <td>0.897437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19422</th>\n",
       "      <td>enfermeiro</td>\n",
       "      <td>0.629140</td>\n",
       "      <td>0.208829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22325</th>\n",
       "      <td>programador</td>\n",
       "      <td>0.521329</td>\n",
       "      <td>0.026923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36288</th>\n",
       "      <td>engenheira</td>\n",
       "      <td>0.094275</td>\n",
       "      <td>0.609618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44580</th>\n",
       "      <td>faxineira</td>\n",
       "      <td>0.143218</td>\n",
       "      <td>0.774388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57204</th>\n",
       "      <td>medico</td>\n",
       "      <td>0.706412</td>\n",
       "      <td>0.152639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64804</th>\n",
       "      <td>faxineiro</td>\n",
       "      <td>0.724001</td>\n",
       "      <td>0.347508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70998</th>\n",
       "      <td>medica</td>\n",
       "      <td>0.197178</td>\n",
       "      <td>0.203410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82295</th>\n",
       "      <td>programadora</td>\n",
       "      <td>-0.035517</td>\n",
       "      <td>0.438952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90732</th>\n",
       "      <td>juiza</td>\n",
       "      <td>0.117268</td>\n",
       "      <td>0.641748</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               word  similarity_homem  similarity_mulher\n",
       "1352           juiz          0.552790           0.063067\n",
       "1611       advogado          0.647213           0.076083\n",
       "3205     engenheiro          0.528756           0.070841\n",
       "8821       advogada          0.103379           0.709269\n",
       "9638     enfermeira          0.145856           0.897437\n",
       "19422    enfermeiro          0.629140           0.208829\n",
       "22325   programador          0.521329           0.026923\n",
       "36288    engenheira          0.094275           0.609618\n",
       "44580     faxineira          0.143218           0.774388\n",
       "57204        medico          0.706412           0.152639\n",
       "64804     faxineiro          0.724001           0.347508\n",
       "70998        medica          0.197178           0.203410\n",
       "82295  programadora         -0.035517           0.438952\n",
       "90732         juiza          0.117268           0.641748"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_genders = ['medico','medica',\n",
    "               'enfermeiro','enfermeira',\n",
    "               'advogado','advogada',\n",
    "               'juiz','juiza',\n",
    "               'engenheiro','engenheira',\n",
    "               'programador','programadora',\n",
    "               'faxineiro','faxineira']\n",
    "cos_df[cos_df['word'].isin(job_genders)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vec_word(string,embedding = word_embedding):\n",
    "    if isinstance(embedding, pd.DataFrame):\n",
    "        vec = np.array(embedding.loc[string])\n",
    "        \n",
    "    else:\n",
    "        vec = embedding.get_vector(string)\n",
    "        \n",
    "    return vec\n",
    "\n",
    "def gvec_word():\n",
    "    return \n",
    "def norm(vec):\n",
    "    return np.linalg.norm(vec)\n",
    "\n",
    "def cos_sim(vec1,vec2):\n",
    "    return (vec1.dot(vec2)/(norm(vec1)*norm(vec2)))\n",
    "\n",
    "def vec_subtr(vec1,vec2):\n",
    "    return np.array(vec1) - np.array(vec2)\n",
    "\n",
    "def normalize(vec):\n",
    "    return vec/norm(vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usaremos o Skipgram 300 dimensões pois as representações fica melhor descrita do que com 50 dimensões"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vectors = KeyedVectors.load_word2vec_format('skip_s300.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('rainha', 0.6600958108901978), ('consorte', 0.6526049375534058), ('esposa', 0.6504771113395691), ('sobrinha', 0.6446163654327393), ('princesa', 0.6398769617080688), ('filha', 0.6342788934707642), ('rainha-viúva', 0.6339502334594727), ('primogénita', 0.6332842707633972), ('princesa-eleitora', 0.6240090727806091), ('meia-irmã', 0.6229891777038574)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('itália', 0.7363957166671753),\n",
       " ('grécia', 0.680385410785675),\n",
       " ('espanha', 0.6282416582107544),\n",
       " ('sicília', 0.6171325445175171),\n",
       " ('etrúria', 0.6072238683700562),\n",
       " ('anonária', 0.5979100465774536),\n",
       " ('sardenha', 0.5940008163452148),\n",
       " ('áustria-hungria', 0.5736516118049622),\n",
       " ('gália', 0.5675926208496094),\n",
       " ('nápoles', 0.5619080066680908)]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#mulher + (rei - homem)\n",
    "result = word_vectors.most_similar(positive=['rei', 'mulher'], negative=['homem'])\n",
    "\n",
    "#word_vectors.get_vector('homem')\n",
    "#most_similar_key, similarity = result\n",
    "print(result)\n",
    "\n",
    "word_vectors.most_similar(positive=['frança', 'roma'], negative=['paris'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_ex1 = word_vectors['rei'] - word_vectors['rainha']\n",
    "vec_ex2 = word_vectors['homem'] - word_vectors['mulher']\n",
    "vec_ex3 = word_vectors['ele'] - word_vectors['ela']\n",
    "vec_ex4 = word_vectors['menino'] - word_vectors['menina']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rei - rainha e (homem - mulher):  0.5032248\n",
      "rei - rainha e (ele - ela):  0.3451421\n",
      "rei - rainha e (menino - menina):  0.39972755\n",
      "\n",
      "homem - mulher e (ele - ela):  0.4465069\n",
      "homem - mulher e (menino - menina):  0.58841366\n",
      "\n",
      "ele - ela e (menino - menina):  0.3610997\n"
     ]
    }
   ],
   "source": [
    "print('rei - rainha e (homem - mulher): ',cos_sim(vec_ex1,vec_ex2))\n",
    "print('rei - rainha e (ele - ela): ',cos_sim(vec_ex1,vec_ex3))\n",
    "print('rei - rainha e (menino - menina): ',cos_sim(vec_ex1,vec_ex4))\n",
    "print()\n",
    "\n",
    "print('homem - mulher e (ele - ela): ',cos_sim(vec_ex2,vec_ex3))\n",
    "print('homem - mulher e (menino - menina): ',cos_sim(vec_ex2,vec_ex4))\n",
    "print()\n",
    "\n",
    "print('ele - ela e (menino - menina): ',cos_sim(vec_ex3,vec_ex4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8942859992384911\n",
      "0.9341597482562065\n"
     ]
    }
   ],
   "source": [
    "d_analista_male = word_vectors.distance(\"homem\", \"chefe\")\n",
    "d_analista_female = word_vectors.distance(\"mulher\", \"chefe\")\n",
    "\n",
    "print(d_analista_male)\n",
    "print(d_analista_female)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.36177993"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos_sim(word_vectors['homem'],word_vectors['motorista'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20728673"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos_sim(word_vectors['mulher'],word_vectors['motorista'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_dim = vec_subtr(word_vectors['homem'],word_vectors['mulher'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
